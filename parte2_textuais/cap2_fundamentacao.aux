\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{monard2003}
\citation{chappelle2006}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Fundamenta\IeC {\c c}\IeC {\~a}o Te\IeC {\'o}rica}{2}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{cap2}{{2}{2}{Fundamentação Teórica}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Aprendizado de M\IeC {\'a}quina}{2}{section.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Representa\IeC {\c c}\IeC {\~a}o da base de dados\relax }}{3}{table.caption.12}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{table-dataset}{{2.1}{3}{Representação da base de dados\relax }{table.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Aprendizado Supervisionado}{3}{subsection.2.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Normaliza\IeC {\c c}\IeC {\~a}o e One-Hot Enconding}{4}{subsection.2.1.2}}
\newlabel{ssec:norm}{{2.1.2}{4}{Normalização e One-Hot Enconding}{subsection.2.1.2}{}}
\newlabel{eq-norm}{{2.1}{4}{Normalização e One-Hot Enconding}{equation.2.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Codifica\IeC {\c c}\IeC {\~a}o One-hot\relax }}{4}{figure.caption.13}}
\newlabel{fig-onehot}{{2.1}{4}{Codificação One-hot\relax }{figure.caption.13}{}}
\citation{hart1967}
\citation{zhang1998}
\citation{haykin2009}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}K-Nearest Neighbors (KNN)}{5}{subsection.2.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Princ\IeC {\'\i }pio dos k-vizinhos mais pr\IeC {\'o}ximos\relax }}{5}{figure.caption.14}}
\newlabel{fig-knn}{{2.2}{5}{Princípio dos k-vizinhos mais próximos\relax }{figure.caption.14}{}}
\newlabel{eq_disteucli}{{2.2}{5}{K-Nearest Neighbors (KNN)}{equation.2.1.2}{}}
\citation{ferneda2006}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Redes Neurais Artificiais}{6}{section.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Inspira\IeC {\c c}\IeC {\~a}o Biol\IeC {\'o}gica e Perceptron}{6}{subsection.2.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Representa\IeC {\c c}\IeC {\~a}o simplificada de um neur\IeC {\^o}nio\relax }}{6}{figure.caption.15}}
\newlabel{fig-neuronio}{{2.3}{6}{Representação simplificada de um neurônio\relax }{figure.caption.15}{}}
\citation{McCulloch1943}
\citation{lippman1987}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Modelo matem\IeC {\'a}tico de um neur\IeC {\^o}nio\relax }}{7}{figure.caption.16}}
\newlabel{fig-perceptron}{{2.4}{7}{Modelo matemático de um neurônio\relax }{figure.caption.16}{}}
\newlabel{eq_activation}{{2.3}{7}{Inspiração Biológica e Perceptron}{equation.2.2.3}{}}
\newlabel{eq-output-percep}{{2.4}{7}{Inspiração Biológica e Perceptron}{equation.2.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Perceptron multicamadas}{7}{subsection.2.2.2}}
\citation{hinton1986}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Multilayer Perceptron. Cada c\IeC {\'\i }rculo representa um neur\IeC {\^o}nio mostrado anteriormente\relax }}{8}{figure.caption.17}}
\newlabel{fig-mlp}{{2.5}{8}{Multilayer Perceptron. Cada círculo representa um neurônio mostrado anteriormente\relax }{figure.caption.17}{}}
\citation{Goodfellow2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Camada Softmax}{9}{subsection.2.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Fun\IeC {\c c}\IeC {\~a}o de Perda(Loss Function)}{9}{subsection.2.2.4}}
\newlabel{eq-eqm}{{2.6}{9}{Função de Perda(Loss Function)}{equation.2.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Otimizadores}{9}{subsection.2.2.5}}
\newlabel{ssec:otimizadores}{{2.2.5}{9}{Otimizadores}{subsection.2.2.5}{}}
\citation{bengio2012}
\citation{adagrad2011}
\citation{adam2014}
\citation{universal1989}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.6}Hiperpar\IeC {\^a}metros de uma Rede Neural}{10}{subsection.2.2.6}}
\citation{towardsdatascience}
\citation{towardsdatascience}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.1}N\IeC {\'u}mero de camadas e neur\IeC {\^o}nios em cada camada}{11}{subsubsection.2.2.6.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.2}Inicializa\IeC {\c c}\IeC {\~a}o dos pesos}{11}{subsubsection.2.2.6.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.3}Fun\IeC {\c c}\IeC {\~a}o de Ativa\IeC {\c c}\IeC {\~a}o}{11}{subsubsection.2.2.6.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Softmax vs ReLU. Imagem tirada do site \textit  {Towards Data Science} \cite  {towardsdatascience}\relax }}{11}{figure.caption.18}}
\newlabel{fig-activations}{{2.6}{11}{Softmax vs ReLU. Imagem tirada do site \textit {Towards Data Science} \cite {towardsdatascience}\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.4}Mini-batches}{11}{subsubsection.2.2.6.4}}
\citation{dropout2014}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.5}Taxa de aprendizado}{12}{subsubsection.2.2.6.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.6}N\IeC {\'u}mero de \IeC {\'e}pocas}{12}{subsubsection.2.2.6.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.7}Regulariza\IeC {\c c}\IeC {\~a}o}{12}{subsection.2.2.7}}
\citation{dropout2014}
\citation{dropout2014}
\citation{camporeceptivo}
\citation{camporeceptivo}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Imagem ilustrando o efeito do Dropout em uma rede neural onde os neur\IeC {\^o}nios marcados foram desativados, for\IeC {\c c}ando a rede nao depender deles, evitando o \textit  {overfitting} \cite  {dropout2014}.\relax }}{13}{figure.caption.19}}
\newlabel{fig-dropout}{{2.7}{13}{Imagem ilustrando o efeito do Dropout em uma rede neural onde os neurônios marcados foram desativados, forçando a rede nao depender deles, evitando o \textit {overfitting} \cite {dropout2014}.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.8}Redes Convolutivas}{13}{subsection.2.2.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Campo receptivo de um neur\IeC {\^o}nio. Fonte: \cite  {camporeceptivo}\relax }}{13}{figure.caption.20}}
\newlabel{fig-campo}{{2.8}{13}{Campo receptivo de um neurônio. Fonte: \cite {camporeceptivo}\relax }{figure.caption.20}{}}
\citation{haykin2009neural}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.8.1}Camada de Convolu\IeC {\c c}\IeC {\~a}o}{14}{subsubsection.2.2.8.1}}
\citation{guedes2017}
\citation{depth}
\citation{depth}
\citation{githubstride}
\citation{githubstride}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Disposi\IeC {\c c}\IeC {\~a}o dos neur\IeC {\^o}nios na camada de convolu\IeC {\c c}\IeC {\~a}o e seu campo receptivo. Fonte: \cite  {depth}\relax }}{15}{figure.caption.21}}
\newlabel{fig-depth}{{2.9}{15}{Disposição dos neurônios na camada de convolução e seu campo receptivo. Fonte: \cite {depth}\relax }{figure.caption.21}{}}
\citation{Goodfellow2016}
\citation{githubstride}
\citation{githubstride}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Neur\IeC {\^o}nios espa\IeC {\c c}ados por stride 1 e 2 das esquerda para a direita respectivamente. Separados \IeC {\`a} direita est\IeC {\~a}o os pesos compartilhados entre todos os neur\IeC {\^o}nios. Fonte: \cite  {githubstride}\relax }}{16}{figure.caption.22}}
\newlabel{fig-stride}{{2.10}{16}{Neurônios espaçados por stride 1 e 2 das esquerda para a direita respectivamente. Separados à direita estão os pesos compartilhados entre todos os neurônios. Fonte: \cite {githubstride}\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.8.2}Camada Pooling}{16}{subsubsection.2.2.8.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Representa\IeC {\c c}\IeC {\~a}o de max-pooling e average-pooling \cite  {githubstride}\relax }}{16}{figure.caption.23}}
\newlabel{fig-pooling}{{2.11}{16}{Representação de max-pooling e average-pooling \cite {githubstride}\relax }{figure.caption.23}{}}
\citation{lecun98}
\citation{lecun98}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.8.3}Normaliza\IeC {\c c}\IeC {\~a}o em lote}{17}{subsubsection.2.2.8.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.8.4}Arquitetura de uma Rede Convolutiva}{17}{subsubsection.2.2.8.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Arquitetura LeNet-5. \cite  {lecun98}\relax }}{17}{figure.caption.24}}
\newlabel{fig-alexnet}{{2.12}{17}{Arquitetura LeNet-5. \cite {lecun98}\relax }{figure.caption.24}{}}
\citation{resnet2015}
\citation{resnet2015}
\citation{resnet2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.9}Redes Residuais}{18}{subsection.2.2.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Bloco Residual. Fonte: \cite  {resnet2015}\relax }}{18}{figure.caption.25}}
\newlabel{fig-resblock}{{2.13}{18}{Bloco Residual. Fonte: \cite {resnet2015}\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}S\IeC {\'e}ries Temporais}{18}{section.2.3}}
\newlabel{eq_TS}{{2.8}{18}{Séries Temporais}{equation.2.3.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Aplica\IeC {\c c}\IeC {\~o}es de S\IeC {\'e}ries Temporais}{19}{subsection.2.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Classifica\IeC {\c c}\IeC {\~a}o de S\IeC {\'e}ries Temporais}{19}{section.2.4}}
\@setckpt{parte2_textuais/cap2_fundamentacao}{
\setcounter{page}{20}
\setcounter{equation}{8}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{4}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{13}
\setcounter{table}{1}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{AM@survey}{0}
\setcounter{parentequation}{0}
\setcounter{float@type}{16}
\setcounter{NAT@ctr}{0}
\setcounter{LT@tables}{2}
\setcounter{LT@chunks}{1}
\setcounter{lstnumber}{1}
\setcounter{IEEEsubequation}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{31}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{algorithm}{0}
\setcounter{lstlisting}{0}
\setcounter{section@level}{1}
}
