\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{monard2003}
\citation{chappelle2006}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Fundamenta\IeC {\c c}\IeC {\~a}o Te\IeC {\'o}rica}{2}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{cap2}{{2}{2}{Fundamentação Teórica}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Aprendizado de M\IeC {\'a}quina}{2}{section.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Representa\IeC {\c c}\IeC {\~a}o da base de dados\relax }}{3}{table.caption.12}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{table-dataset}{{2.1}{3}{Representação da base de dados\relax }{table.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Aprendizado Supervisionado}{3}{subsection.2.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Normaliza\IeC {\c c}\IeC {\~a}o e One-Hot Enconding}{4}{subsection.2.1.2}}
\newlabel{eq-norm}{{2.1}{4}{Normalização e One-Hot Enconding}{equation.2.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Codifica\IeC {\c c}\IeC {\~a}o One-hot\relax }}{4}{figure.caption.13}}
\newlabel{fig-onehot}{{2.1}{4}{Codificação One-hot\relax }{figure.caption.13}{}}
\citation{hart1967}
\citation{zhang1998}
\citation{haykin2009}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}K-Nearest Neighbors (KNN)}{5}{subsection.2.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Princ\IeC {\'\i }pio dos k-vizinhos mais pr\IeC {\'o}ximos\relax }}{5}{figure.caption.14}}
\newlabel{fig-knn}{{2.2}{5}{Princípio dos k-vizinhos mais próximos\relax }{figure.caption.14}{}}
\newlabel{eq_disteucli}{{2.2}{5}{K-Nearest Neighbors (KNN)}{equation.2.1.2}{}}
\citation{ferneda2006}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Redes Neurais Artificiais}{6}{section.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Inspira\IeC {\c c}\IeC {\~a}o Biol\IeC {\'o}gica e Perceptron}{6}{subsection.2.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Representa\IeC {\c c}\IeC {\~a}o simplificada de um neur\IeC {\^o}nio\relax }}{6}{figure.caption.15}}
\newlabel{fig-neuronio}{{2.3}{6}{Representação simplificada de um neurônio\relax }{figure.caption.15}{}}
\citation{McCulloch1943}
\citation{lippman1987}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Modelo matem\IeC {\'a}tico de um neur\IeC {\^o}nio\relax }}{7}{figure.caption.16}}
\newlabel{fig-perceptron}{{2.4}{7}{Modelo matemático de um neurônio\relax }{figure.caption.16}{}}
\newlabel{eq_activation}{{2.3}{7}{Inspiração Biológica e Perceptron}{equation.2.2.3}{}}
\newlabel{eq-output-percep}{{2.4}{7}{Inspiração Biológica e Perceptron}{equation.2.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Perceptron multicamadas}{7}{subsection.2.2.2}}
\citation{hinton1986}
\citation{Goodfellow2016}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Multilayer Perceptron. Cada c\IeC {\'\i }rculo representa um neur\IeC {\^o}nio mostrado anteriormente\relax }}{8}{figure.caption.17}}
\newlabel{fig-mlp}{{2.5}{8}{Multilayer Perceptron. Cada círculo representa um neurônio mostrado anteriormente\relax }{figure.caption.17}{}}
\citation{bengio2012}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Camada Softmax}{9}{subsection.2.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Fun\IeC {\c c}\IeC {\~a}o de Perda(Loss Function)}{9}{subsection.2.2.4}}
\newlabel{eq-eqm}{{2.6}{9}{Função de Perda(Loss Function)}{equation.2.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Otimizadores}{9}{subsection.2.2.5}}
\citation{adagrad2011}
\citation{adam2014}
\citation{universal1989}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.6}Hiperpar\IeC {\^a}metros de uma Rede Neural}{10}{subsection.2.2.6}}
\citation{towardsdatascience}
\citation{towardsdatascience}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.1}N\IeC {\'u}mero de camadas e neur\IeC {\^o}nios em cada camada}{11}{subsubsection.2.2.6.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.2}Inicializa\IeC {\c c}\IeC {\~a}o dos pesos}{11}{subsubsection.2.2.6.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.3}Fun\IeC {\c c}\IeC {\~a}o de Ativa\IeC {\c c}\IeC {\~a}o}{11}{subsubsection.2.2.6.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Softmax vs ReLU. Imagem tirada do site \textit  {Towards Data Science} \cite  {towardsdatascience}\relax }}{11}{figure.caption.18}}
\newlabel{fig-activations}{{2.6}{11}{Softmax vs ReLU. Imagem tirada do site \textit {Towards Data Science} \cite {towardsdatascience}\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.4}Mini-batches}{11}{subsubsection.2.2.6.4}}
\citation{dropout2014}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.5}Taxa de aprendizado}{12}{subsubsection.2.2.6.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.6}N\IeC {\'u}mero de \IeC {\'e}pocas}{12}{subsubsection.2.2.6.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.7}Regulariza\IeC {\c c}\IeC {\~a}o}{12}{subsection.2.2.7}}
\citation{dropout2014}
\citation{dropout2014}
\citation{cnn01}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Imagem ilustrando o efeito do Dropout em uma rede neural onde os neur\IeC {\^o}nios marcados foram desativados, for\IeC {\c c}ando a rede nao depender deles, evitando o \textit  {overfitting} \cite  {dropout2014}.\relax }}{13}{figure.caption.19}}
\newlabel{fig-dropout}{{2.7}{13}{Imagem ilustrando o efeito do Dropout em uma rede neural onde os neurônios marcados foram desativados, forçando a rede nao depender deles, evitando o \textit {overfitting} \cite {dropout2014}.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.8}Redes Convolutivas}{13}{subsection.2.2.8}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}S\IeC {\'e}ries Temporais}{14}{section.2.3}}
\newlabel{eq_TS}{{2.8}{14}{Séries Temporais}{equation.2.3.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Aplica\IeC {\c c}\IeC {\~o}es de S\IeC {\'e}ries Temporais}{15}{subsection.2.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Classifica\IeC {\c c}\IeC {\~a}o de S\IeC {\'e}ries Temporais}{15}{section.2.4}}
\@setckpt{parte2_textuais/cap2_fundamentacao}{
\setcounter{page}{16}
\setcounter{equation}{8}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{4}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{7}
\setcounter{table}{1}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{AM@survey}{0}
\setcounter{parentequation}{0}
\setcounter{float@type}{16}
\setcounter{NAT@ctr}{0}
\setcounter{LT@tables}{2}
\setcounter{LT@chunks}{1}
\setcounter{lstnumber}{1}
\setcounter{IEEEsubequation}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{26}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{algorithm}{0}
\setcounter{lstlisting}{0}
\setcounter{section@level}{1}
}
