\chapter{Fundamentação Teórica} \label{cap2}


Este capítulo aborda, de forma sucinta, os fundamentos teóricos que foram aplicados no planejamento e implementaçao deste projeto.



\section{Aprendizado de Máquina}

Aprendizado de máquina(AM) é uma área da inteligência artificial cujo objetivo é o desenvolvimento de técnicas computacionais sobre o aprendizado, bem como a construção de sistemas capazes de adquirir conhecimento de forma automática. Um sistema baseado em aprendizado trabalha por meio de experiências acumuladas e de soluções bem-sucedidas de problemas anteriores  \cite{monard2003}. Normalmente, algoritmos de aprendizado utilizam experiências anteriores, denominadas conjunto de treino, para auxiliar no processo de tomada de decisão.  

Existem três diferentes tipos de aprendizado: supervisionado, não-supervisionado e semi-supervisionado. A diferença entre esses tipos de aprendizado é se o método utiliza ou não utiliza o rótulo de teino. No aprendizado supervisionado, esse rótulo é conhecido, enquanto que no aprendizado não-supervisionado os exemplos não vistos. Já no aprendizado semi-supervisionado, o conjunto de treinamento consiste de uns poucos exemplos rotulados e muitos não rotulados\cite{chappelle2006}. O escopo deste trabalho se encontra no aprendizado supervisionado. 


\subsection{Aprendizado Supervisionado}
O objetivo do aprendizado supervisionado é construir um modelo que consegue fazer predição através de instâncias de uma base de dados rotuladas. Cada instância é representada por um conjunto de características. Na Tabela \ref{table-dataset} é mostrada a estrutura de uma base. Neste exemplo cada vetor $E_i = [x_{i1},...,x_{iM}]$ se refere a classe $y_i$.

A idéia da aprendizagem supervisionada é o conseguir encontrar uma função desconhecida $f$(função conceito) tal que $y=f(\mathbf{x})$, onde o vetor $\mathbf{x}$ são os atributos de uma instância específica. Na prática, a função $f$ deve conseguir prever o valor correto $y_i$ de uma instância $E_i$ não vista. Normalmente, o número de exemplos da base de dados não é suficiente para descrever a função conceito. Nesse caso, o classificador é visto como uma hipótese $h$ que aproxima $f$, ou seja, $h(x)\approx f(x)$ . Caso os valores dos rótulos $y_1,y_2,...,y_N$ sejam numéricos o problema é denominado de \textit{regressão}, caso sejam valores categóricos o problema é denominado de \textit{classificação}. 

\begin{table}[]
	\centering
	\begin{tabular}{c|cccc|c}
		\hline
		& $A_1$ & $A_2$ & \dots & $A_M$  & Classe(Y) \\
		\hline 
		\hline
		$E_1$ & $x_{11}$ & $x_{12}$ & \vdots & $x_{1M}$ & $y_1$ \\
		$E_2$ & $x_{21}$ & $x_{22}$ & \vdots & $x_{2M}$ & $y_2$ \\
		\vdots & \vdots & \vdots &  $\ddots$ & \vdots & \vdots \\
		$E_N$ & $x_{N1}$ & $x_{N2}$ & \vdots & $x_{NM}$ & $y_N$ \\
		\hline
		
		
	\end{tabular}	
	\caption{Representação da base de dados}
	\label{table-dataset}
\end{table}


De maneira geral, a base de dados é dividida em dois conjuntos: conjunto de \textit{treino} e conjunto de \textit{teste}. O conjunto de treinamento é utilizado para ajustar o classificador. Como dito anteriormente, o classificador é uma hipótese da função conceito $f$ ,logo, é fundamental que o conjunto de treinamento tenha uma distribuição o mais semelhante possível do conjunto original.  O conjunto de teste é utilizado para avaliar o modelo construído. Idealmente, esse conjunto não deve ter exemplos em comum com o conjunto de treinamento.

Em alguns casos, pode ser necessário utilizar um conjunto de \textit{validação}, extraído do conjunto de treinamento, para realizar ajustes no modelo construído pelo algoritmo de aprendizado. Logo tem-se três conjuntos: \textit{treino}, \textit{validação} e \textit{teste}. O treino é utilizado para aprendizagem do algoritmo. O modelo é avaliado através do conjunto de validação. É feita uma alteração dos parâmetros do classificador e outro treinamento é realizado. O intuito é melhorar o desempenho do modelo através desses "ajustes". Dessa maneira os exemplos de validação são indiretamente "vistos" durante o processo de aprendizado, o que obriga que esses exemplos sejam diferentes dos exemplos de testes.

\subsection{Normalização e One-Hot Enconding}
Os algoritmos de aprendizagem de máquina aprendem através dos dados. Dados do mundo real apresentam valores que estão em distintas faixas. A fim de evitar que algum atributo predomine sobre outro ou que inclua alguma ponderação indesejada ao induzir um modelo de AM, é comum fazer uma normalização dos valores de cada atributo. Um forma de normalizar os dados é mostrada na Equação \ref{eq-norm}:

\begin{equation}\label{eq-norm}
x_{ij} = \frac{x_{ij} - \overline{x}}{ \sigma_j}
\end{equation}

onde $\overline{x}$ representa a média do atributo e $\sigma_j$ representa o desvio padrão.

Os algoritmos de AM geralmente possuem como entrada e saída valores numéricos, portanto é necessário converter os valores categóricos da base de dados para valores numéricos. A codificação one-hot é um processo que converte rótulos em vetores binários como mostrado na Figura \ref{fig-onehot}. Uma vantagem dessa codificação é que não cria uma "ordem" numérica nos dados. Essa ordem poderia interferir na indução do classificador, podendo dar maior importância para valores maiores, o que não faz sentido para variáveis categóricas.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{pasta1_figuras/one-hot.png}
	\caption{Codificação One-hot}
	\label{fig-onehot}
\end{figure}

\subsection{K-Nearest Neighbors (KNN)}
Um classificador bastante popular é o K-Nearest Neighbors(K-Vizinhos mais próximos). O KNN utiliza os próprios dados de treinamento como modelo de classificação. Para classificar uma instância de teste, procura-se entre os dados de treinamento os $K$ mais próximos da instância de teste. Por fim, verifica-se qual a classe predominante desses $K$ dados de treinamento, e instância de teste é classificada com essa mesma classe. A cada nova exemplo a ser classificado faz-se uma varredura nos dados de treinamento, o que provoca um grande esforço computacional

O princípio do classificador k-NN é a ``regra dos vizinhos mais próximos''. A hipótese é que, dado um conjunto de exemplos distribuídos sobre o espaço de dados $X$, a ``vizinhança'' de um exemplo $x \in X$ estabelecida por uma função de distância apropriada tende a ser ocupada por exemplos que pertencem à mesma classes que $x$ \cite{hart1967} , como ilustrado na Figura \ref{fig-knn}. Desse modo a informação fornecida pelos exemplos conhecidos que são mais similares a $x$.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{pasta1_figuras/knn.png}
	\caption{Princípio dos k-vizinhos mais próximos}
	\label{fig-knn}
\end{figure}

Para encontrar os vizinhos mais próximos é necessário definir uma medida de similaridade entre dois exemplos. Uma medida de similaridade bastante popular é a \textit{distância euclidiana}. Tal medida calcula a raiz quadrada da norma do vetor diferença entre os vetores $x$ e $y$:
\begin{equation} \label{eq_disteucli}
d(x,y)= \sum_{i=1}^{K} (x_i - y_i)^2
\end{equation}

\section{Redes Neurais Artificiais}
Redes Neurais Artificais são modelos computacionais que buscam simular o processamento de informação pelo cérebro humano. Elas são compostas por unidades simples de processamento, os neurônios, que se unem por meio de conexões sinápticas \cite{zhang1998}. Cada conexão, além de ser altamente especializada, é responsável pelo envio de sinais de um neurônio para outro. Segundo (\textit{Haykin} 2009\cite{haykin2009}) , os neurônios e suas conexões podem ser implementados utilizando-se de componentes eletrônicos ou via simulação programada em computador.

\subsection{Inspiração Biológica e Perceptron}

Um bloco básico de uma rede neural tem algumas semelhanças com um neurônio biológico. O neurônio biológico é uma célula formada por três seçoes com funções específicas e complementares: \textit{corpo},\textit{dentritos} e \textit{axônio}. Os dentritos captam os estímulos recebidos em um determinado período de tempo e os transmitem ao corpo do neurônio, onde são processados. Quando tais estímulos atingirem determinado limite, o corpo da célula envia um novo impulso que se propaga pelo axônio e é transmitido às células vizinhas por meio de sinapses.  Este processo pode se repetir em várias camadas de neurônios. Como resultado, a informação de entrada é processada, podendo levar o cérebro a comandar reações físicas.  \cite{ferneda2006}. A figura \ref{fig-neuronio} ilustra de forma simplificada as partes de um neurônio.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{pasta1_figuras/neuronio.png}
	\caption{Representação simplificada de um neurônio}
	\label{fig-neuronio}
\end{figure}

O modelo de um neurônio artifical é apresentado na Figura \ref{fig-guide-1}. Este modelo é composto por três elementos:
\begin{itemize}
	\item Um cojunto de entradas $(x_1,x_2,...,x_n)$ que são multiplicadas por um conjunto e pesos $(p_1,p_2,...,p_n)$;
	\item Um somador $(\sum)$ para acumular o sinais de entrada;
	\item Uma função de ativação que ($\varphi$) limita o intervalo permissível de amplitude do sinal de saída (y) a um valor fixo.
\end{itemize}

\textbf{\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{pasta1_figuras/perceptron.png}
	\caption{Modelo matemático de um neurônio}
	\label{fig-perceptron}
\end{figure}}

Esse modelo foi proposto por \textit{McCulloch and Pitts} em 1943 \cite{McCulloch1943} e é conhecido como \textit{perceptron}. A função de ativação ($\varphi$) tem a seguinte definição:
\begin{equation} \label{eq_activation}
\varphi = \left\{ \,
\begin{IEEEeqnarraybox}[][c]{l?s}
\IEEEstrut
1 & if $\sum_{i=1}^{n} p_i x^k_i \geq T$, \\
0 & if $\sum_{i=1}^{n} p_i x^k_i < T$ 
\IEEEstrut
\end{IEEEeqnarraybox}
\right.
\end{equation}
Os valores dos pesos podem ser positivos ou negativos e eles refletem se aquela conexão é inibitória ou excitatória. Um valor positivo ou negativo reflete a importância da respectiva entrada para o processamento. Frequentemente é adicionado um \textit{viés} $b$ na entrada da função de ativação. A forma geral do modelo é descrito como:
\begin{equation} \label{eq-output-percep}
y(k) = \varphi(\sum_{i=1}^{n} p_i(k) x_i(k) +b(k))
\end{equation}
Os pesos sinápticos do Perceptron podem ser adaptados empregando um processo de aprendizado com um número finito de iterações. A aprendizagem é conduzida pela regra de correção de erro conhecida como algoritmo de convergência do Perceptron. Esse algoritmo visa encontrar um vetor de pesos $w$ tal que as duas igualdades da função degrau sejam satisfeitas(\textit{Lippmann}, 1987 \cite{lippman1987})

\subsection{Perceptron multicamadas}

O Perceptron multicamadas(\textit{Multi-Layer Perceptron - MLP}) é uma generalização da rede perceptron. Novas camadas são adicionadas o que possibilita a solução de problemas que não sejam linearmente separáveis. O vetor de entradas \textbf{x} passa pela camada inicial, cujos valores de saída são ligados a camada seguinte. Esse processo se repete até chegar na última camada.(Figura \ref{fig-mlp})  Pode-se arranjar a rede em várias camadas, tornando-a profunda e capaz de aprender relações cada vez mais complexas.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{pasta1_figuras/mlp.png}
	\caption{Multilayer Perceptron. Cada círculo representa um neurônio mostrado anteriormente}
	\label{fig-mlp}
\end{figure}

Em 1986, \textit{Rumelhart, Hinton e Williams} \cite{hinton1986} desenvolveram o algoritmo \textit{backpropagation}, que utiliza o gradiente descendente para treinar uma MLP. Este método é composto pelas fases \textit{forward} e \textit{backward}. O objetivo do backpropagation é otimizar os pesos para que a rede neural possa aprender a mapear corretamente as entradas para as saídas. A primeira fase é a ``propragação adiante'' (forward), onde as entradas inseridas na rede se propagam entre as camadas, uma a uma, até a produção das respectivas saídas, portanto a função dessa fase é gerar uma resposta considerando as entradas e os respectivos pesos sinápticos, os quais permanecem inalterados.

Na fase backward é onde a aprendizagem dos pesos é realizada. Esse aprendizado se dá através da otimização (minimização) da função loss, a qual determina a qualidade da classificação do dado de entrada.Essa otimização é realizada através de um método chamado \textit{Gradiente Descendente} que busca a minimização da função \textit{loss} ao alterar os pesos na direção de maior declive do gradiente. O gradiente é calculado na última camada e então é retro-propragado para as camadas intermediárias anteriores que contribuem diretamente para a formação da saída. Cada elemento da camada intermediária recebe é responsável apenas por uma porção do gradiente total. Este processo se repete, camada por camada, até que cada elemento tenha a sua parcela de gradiente para o gradiente total. Baseado no gradiente, é feita uma alteração dos valores dos pesos e bias de modo que a rede aprenda os padrões do conjunto de treinamento.

\subsection{Otimizadores}
Existem diversas variantes do gradiente descendente, que diferem na forma do cálculo da atualização dos pesos da rede. 

\begin{itemize}
	\item Stochastic Gradient Descent
	\item Momentum
	\item RMSprop
	\item AdaDelta
	\item Adam
\end{itemize}

\subsection{Camada Softmax}

Como explicado em \textit{GoodFellow, Bengio, e Courville}(2016 \cite{Goodfellow2016}), a camada softmax é utilizada como um classificador na camada de saída e tem como objetvio representar a probabilidade de cada classe para cada valor de entrada.

Pela Equação 3.5 nota-se que os valores de saída da camada softmax estão entre 0 e 1, e que a soma de de todas as saídas é igual a 1. Desta forma, cada neurônio de saída representa representa a probabilidade da entrada pertencer a uma determinada classe.

\begin{equation}
softmax(z_i) = \frac{exp(z_i)}{\sum_{j}^{} exp(z_j)}
\end{equation}

\subsection{Função de Perda(Loss Function)}
A função de perda compara a saída da rede para um exemplo de treinamento com o rótulo verdadeiro. Uma função de perda comum é o erro médio quadrático dado pela Equação \ref{eq-eqm}

\begin{equation} \label{eq-eqm}
MSE = 	\frac{ \sum_{i=1}^{N} (y_i - \hat{y_i})^2}{N}
\end{equation}

Quando a saída da rede neural está sendo tratada como uma distribuição de probabilidade é comum utilizar entropria cruzada \textit{cross-entropy}. Ela é usada para quantificar a distâncias entre duas distribuições de probabilidade. Em redes neurais a entropria cruzada comparada a distribuição do que o modelo prediz com a previsão. Ela é definida como:
\begin{equation}
L = - \sum_{i}^{} y_i log(z_i)
\end{equation}
Para problemas de classificação a entropria cruzada é mais adequada.




Neste trabalho foi utilizado o otimizador Adam, além de ser


\subsection{Hiperparâmetros de uma Rede Neural}
A maioria dos algoritmos de AM envolvem "hiperparâmetros", que são varíaveis definidas para o algoritmo antes do treinamento com o objetivo de otimizá-lo. Definir os valores de hiperparâmetros pode ser visto como uma seleção de modelos, ou seja, escolher qual modelo usar do conjunto hipotético de modelos possíveis. Em redes neurais os hiperparâmeteros determinam a estrutura da rede (Ex: Número de neurônios em uma camada) ou como a rede será treinada(Ex: Taxa de aprendizado)

\subsubsection{Mini-batches}
O treinamento geralmente é realizado em \textit{batches} também conhecidos como \textit{mini-batches} que são subconjuntos do treino. As razões de utilizar batches e não o treino inteiro são: diminuição do tempo de treinamento; caso o conjunto de treino seja suficientemente grande, uma amostra desse conjunto pode representar de forma \textit{boa} o conjunto original. A tamanho dessa amostra é um hiperparâmetro da rede, sendo geralmente aceito que o treinamento com \textit{batches} maiores resulta numa melhor performance.

\subsubsection{Taxa de aprendizado}

A taxa de aprendizado é um parâmetro constante no intervalo de [0,1] que interfere na convergência do aprendizado. Ela determina o quão ``rápido" as atualizações dos pesos irão em direção do gradiente. Se a taxa de aprendizado for muito pequena, o modelo convergirá muito lentamente; Se a taxa de aprendizado for muito grande, o modelo irá divergir. 





\section{Séries Temporais}

Série temporal é uma sequência de observações de um fenômeno ao longo do tempo. Geralmente essas medições são feitas em um intervalo de tempo regular. A ordem das amostras é crucial, pois há um dependência entre os dados e uma alteração da ordem pode modificar o significado dos dados. Uma série temporal pode ser definida como:

\begin{equation} \label{eq_TS}
X(t) = (x_1,x_2,...,x_n)
\end{equation}
onde $x_n$ representa uma observação no instante $t$, $n$ o número de observações e $X(t)$ a função que descreve a série temporal em termos de t. Caso a série seja constituída de uma observação em cada instante de tempo ela é chamada de \textit{univariada}. Caso a série foi obtida por uma coleta simultânea de dois ou mais fenômenos ela é chamada de \textit{multivariada}.

As séries temporais estão em diversas áreas do conhecimento como Economia (preços diários dea ações, taxa mensal de desemprego, produção industrial), Medicina (eletrocardiograma, eletroencefalograma), Epidemiologia (número mensal de novos casos de meningite), Meteorologia( precipitação pluviométrica, temperatura diária, velocidade do vento).

\subsection{Aplicações de Séries Temporais}
A análise de séries temporais tem atraído muitos pesquisadores em aprendizado de máquina ao redor do mundo. As principais tarefas envolvendo séries temporais na qual se utiliza aprendizagem de máquina são as seguintes:

\begin{itemize}
	\item \textit{Classificação}: cada série temporal representa uma classe distinta de objetos. Dada uma série temporal, o objetivo é descobrir qual é a classe de objetos ela representa; 
	\item Agrupamento: Dado um conjunto de séries temporais, o objetivo é encontrar uma estrutura natural que permita distribuir as séries em grupos; 
	\item Detecção de Motivos: também conhecido como detecção de \textit{motifs}; o objetivo é encontrar uma ou mais subsequências que aparecem frequentemente na séries;
	\item Detecção de Anomalias: encontrar subsequências ou séries que são inesperadas em algum contexto.
\end{itemize}
Este trabalho está inserido na tarefa de classificações de séries temporais.
\section{Classificação de Séries Temporais}



% Fim Capítulo