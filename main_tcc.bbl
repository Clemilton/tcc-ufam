\providecommand{\abntreprintinfo}[1]{%
 \citeonline{#1}}
\begin{thebibliography}{}
\providecommand{\abntrefinfo}[3]{}
\providecommand{\abntbstabout}[1]{}
\abntbstabout{v-1.9.6 }

\bibitem{towardsdatascience}
\abntrefinfo{{Towards Data Science}}{{Towards Data Science}}{2017}
{{Towards Data Science}. \emph{Activations Functions: Neural Networks}. 2017.
[Online; acessado em 18 de Dezembro, 2013].
Dispon{\'\i}vel em:
  $<$https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6$>$.}

\bibitem{dropout2014}
\abntrefinfo{Srivastava et al.}{SRIVASTAVA et al.}{2014}
{SRIVASTAVA, N. et al. Dropout: A simple way to prevent neural networks from
  overfitting.
\emph{Journal of Machine Learning Research}, v.~15, p. 1929--1958, 2014.
Dispon{\'\i}vel em: $<$http://jmlr.org/papers/v15/srivastava14a.html$>$.}

\bibitem{camporeceptivo}
\abntrefinfo{{neuroclusterbrain.com}}{{neuroclusterbrain.com}}{2017}
{{neuroclusterbrain.com}. \emph{Neuron model RF-PSTH}. 2017.
[Online; acessado em 08 de Janeiro, 2019].
Dispon{\'\i}vel em: $<$http://neuroclusterbrain.com$>$.}

\bibitem{monard2003}
\abntrefinfo{Monard e Baranauskas}{MONARD; BARANAUSKAS}{2003}
{MONARD, M.; BARANAUSKAS, J. \emph{Conceitos sobre aprendizado de máquinas. Em
  Sistemas Inteligentes: Fundamentos e Aplicações}. 1º. ed. [S.l.]: Editora
  Manole, 2003.}

\bibitem{chappelle2006}
\abntrefinfo{Chapelle, Schölkopf e Zien}{CHAPELLE; SCHöLKOPF; ZIEN}{2006}
{CHAPELLE, O.; SCHöLKOPF, B.; ZIEN, A. \emph{Semi-Supervised Learning.} 1º.
  ed. [S.l.]: MIT Press, Cambridge, 2006. 12 -- 13~p.}

\bibitem{hart1967}
\abntrefinfo{Cover e Hart}{COVER; HART}{1967}
{COVER, T.; HART, P. Nearest neighbor pattern classification.
\emph{Information Theory, IEEE Transaction on}, 1967.}

\bibitem{zhang1998}
\abntrefinfo{Zhang, Patuwo e Hu}{ZHANG; PATUWO; HU}{1998}
{ZHANG, G.; PATUWO, B.~E.; HU, M.~Y. Forecasting with artificial neural
  networks: The state of art.
\emph{International Journal of Forecasting}, 1998.}

\bibitem{haykin2009}
\abntrefinfo{Haykin}{HAYKIN}{}
{HAYKIN, S.~S. \emph{Neural networks and learning machines}. 3º. ed. Upper
  Saddle River, United States of America: Prentice Hall.}

\bibitem{ferneda2006}
\abntrefinfo{Ferneda}{FERNEDA}{2006}
{FERNEDA, E. Redes neurais e sua aplicação em sistemas de recuperação de
  informação.
\emph{Ciência da Informação}, v.~35, n.~1, 2006.
ISSN 1518-8353.
Dispon{\'\i}vel em: $<$http://revista.ibict.br/ciinf/article/view/1149$>$.}

\bibitem{McCulloch1943}
\abntrefinfo{McCulloch e Pitts}{MCCULLOCH; PITTS}{1943}
{MCCULLOCH, W.~S.; PITTS, W. A logical calculus of the ideas immanent in
  nervous activity.
\emph{The bulletin of mathematical biophysics}, 1943.
ISSN 1522-9602.
Dispon{\'\i}vel em: $<$https://doi.org/10.1007/BF02478259$>$.}

\bibitem{lippman1987}
\abntrefinfo{Lippmann}{LIPPMANN}{1987}
{LIPPMANN, R. An introduction to computing with neural nets.
\emph{IEEE ASSP Magazine}, v.~4, n.~2, 1987.}

\bibitem{hinton1986}
\abntrefinfo{Rumelhart, Hinton e Williams}{RUMELHART; HINTON; WILLIAMS}{1986}
{RUMELHART, D.~E.; HINTON, G.~E.; WILLIAMS, R.~J. Learning representations by
  back-propagating errors.
\emph{Nature}, Nature Publishing Group, v.~323, p. 533--, out. 1986.
Dispon{\'\i}vel em: $<$http://dx.doi.org/10.1038/323533a0$>$.}

\bibitem{Goodfellow2016}
\abntrefinfo{Goodfellow, Bengio e Courville}{GOODFELLOW; BENGIO;
  COURVILLE}{2016}
{GOODFELLOW, I.; BENGIO, Y.; COURVILLE, A. \emph{Deep Learning}. [S.l.]: MIT
  Press, 2016. \url{http://www.deeplearningbook.org}.}

\bibitem{bengio2012}
\abntrefinfo{Bengio, Boulanger{-}Lewandowski e Pascanu}{BENGIO;
  BOULANGER{-}LEWANDOWSKI; PASCANU}{2012}
{BENGIO, Y.; BOULANGER{-}LEWANDOWSKI, N.; PASCANU, R. Advances in optimizing
  recurrent networks.
\emph{CoRR}, abs/1212.0901, 2012.
Dispon{\'\i}vel em: $<$http://arxiv.org/abs/1212.0901$>$.}

\bibitem{adagrad2011}
\abntrefinfo{Duchi, Hazan e Singer}{DUCHI; HAZAN; SINGER}{2011}
{DUCHI, J. C.; HAZAN, E.; SINGER, Y. Adaptive subgradient methods for online
  learning and stochastic optimization.
\emph{Journal of Machine Learning Research}, v.~12, p. 2121--2159, 07 2011.}

\bibitem{adam2014}
\abntrefinfo{Kingma e Ba}{KINGMA; BA}{2014}
{KINGMA, D.~P.; BA, J. Adam: {A} method for stochastic optimization.
\emph{CoRR}, abs/1412.6980, 2014.
Dispon{\'\i}vel em: $<$http://arxiv.org/abs/1412.6980$>$.}

\bibitem{universal1989}
\abntrefinfo{Cybenko}{CYBENKO}{1989}
{CYBENKO, G. Approximation by superpositions of a sigmoidal function.
\emph{Mathematics of Control, Signals, and Systems. 1989 Springer-Verlag New
  York Inc}, p. 303--314, 1989.}

\bibitem{haykin2009neural}
\abntrefinfo{Haykin}{HAYKIN}{2009}
{HAYKIN, S.~S. \emph{Neural networks and learning machines}. Third. Upper
  Saddle River, NJ: Pearson Education, 2009.}

\end{thebibliography}
